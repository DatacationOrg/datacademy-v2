{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Assignment: Datacademy - Auction data\n",
    "You will be working with a real-world data set, that is collected by a `digital auction house`. <br>\n",
    "As a data professional, your task is to use this data to improve the process of the auction house. <br>\n",
    "The data consist of three related tables: `auctions`, `lots` and `bids`. <br>\n",
    "Auctions concern the actual events at which lots (items) are auctioned, after which the bids table contains all bids placed. <br>\n",
    "A more detailed overview of what these tables are comprised of is given below:\n",
    "\n",
    "1. Table `auctions` with columns:\n",
    "   * `id`: the auction id, uniquely identifying an auction (`int`).\n",
    "   * `relatedCompany`: the concerning company for which the items will be auctioned (`str`).\n",
    "   * `auctionStart`: the date and time at which the auction started (`datetime.date`).\n",
    "   * `auctionEnd`: the date and time at which the auction ended (`datetime.date`).\n",
    "   * `branchCategory`: the branch to which the product to be auctioned are categorized (`str`).\n",
    "2. Table `lots` with columns:\n",
    "   * `countryCode`: description of the country the lot is auctioned in (`str`).\n",
    "   * `saleDate`: the date and time at which the lot is sold (`datetime.date`).\n",
    "   * `auctionID`: the id reference of the auction at which the lot is offered (`int`).\n",
    "   * `lotNr`: the numeric indicator of the lot within its auction (`int`). \n",
    "   * `suffix`: additional information to the lot number (`str`).\n",
    "   * `numberOfItems`: the number of items offered within the lot (`int`).\n",
    "   * `buyerAccountID`: the id of the bidder who won the auction and bought the lot (`int`).\n",
    "   * `estimatedValue`: the estimated value of the items comprising the lot (`float`).\n",
    "   * `StartingBid`: the initial price for which the lot is offered (`float`).\n",
    "   * `reserveBid`: the minimum amount that the seller will accept as the winning bid (`int`).\n",
    "   * `currentBid`: the actual bid offered for the auctioned lot (`float`).\n",
    "   * `vat`: the percentage tax payed for the auctioned lot (`int`).\n",
    "   * `category`: the category of products to which this lot is assigned (`str`).\n",
    "   * `sold`: indicator whether the lot is sold or is left unsold (`int`).\n",
    "3. Table `bids` with columns:\n",
    "   * `auctionID`: the id reference of the auction at which the lot is offered (`int`).\n",
    "   * `lotNr`: the numeric indicator of the lot in which the bid is made (`int`).\n",
    "   * `lotID`: reference ID describing the lot in which the bid is made (`int`).\n",
    "   * `isCombination`: indicator if the bid is considered within a combination of bids (`int`).\n",
    "   * `accountID`: the id of the bidder who placed the bid (`int`).\n",
    "   * `isCompany`: indicator whether the bidder concerns a company (`int`).\n",
    "   * `bidPrice`: the price the bidder offered (`int`).\n",
    "   * `biddingDateTime`: the time the bid was placed by the bidder (`datetime.date`).\n",
    "   * `closingDateTime`: the time the lot is planned to close(`datetime.date`).\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## A. Import libraries\n",
    "\n",
    "Installation of all Python libraries is done using `poetry`, when we created the `environment` in the setup. <br>\n",
    "Below all libraries are imported and are given the correct `aliasses`, which are often used in practice. <br>\n",
    "You simply have the run the code cell and you can start creating! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "modulePath = \"/Modules/M10_FINAL/src\"\n",
    "dataPath = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacademy.modules import Module10\n",
    "\n",
    "module = Module10(server_address='https://devdatacademyapi.azurewebsites.net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## B. Descriptive Analytics\n",
    "All Data Science projects start by getting a clear understanding of the data. <br>\n",
    "This section will guide you through the steps to execute descriptive analytics and familiarize yourself with the available data. <br>\n",
    "We set out some logical steps that would normally be included in such an initial data review. <br>\n",
    "These steps utilize basic Python (/Pandas) functions, used to do the follow:\n",
    "\n",
    "* `Read the data` - Read the data from the given data source.\n",
    "* `Quick view` - Look at the first x rows of the data set.\n",
    "* `Missing values` - Investigate the amount of missing values.\n",
    "* `Outliers` - Review the numerical ranges in the data set.\n",
    "* `Analyze categories` - Investigate the distribution over the available categories.\n",
    "\n",
    "Execution of these steps will give you a basic understanding of your data. <br>\n",
    "Basic understanding is sufficient for now, the rest will come when you start building and training your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. Read the data\n",
    "As you will be working with larger data sets, we share them in a more suitable way. <br>\n",
    "`Parquet` is a data format designed to handle large amounts of data. <br>\n",
    "Reading them can be done in a similar way as we did with `CSV` files in the past. <br>\n",
    "However, now we use the command <code>pd.read_parquet()</code> and the file extension <code>.parquet</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Read the auctions, lots and bids using the dataPath\n",
    "auctions = pd.read_parquet(dataPath+\"/auctions.parquet\")\n",
    "lots = pd.read_parquet(dataPath+\"/lots.parquet\")\n",
    "bids = pd.read_parquet(dataPath+\"/bids.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. Quick view\n",
    "To start we quickly review the first rows of the different data frames. <br>\n",
    "In doing so, we get a feeling for the structure of the data frame and the actual content that is in there. <br>\n",
    "The `.head()` function returns by default the first 5 rows. <br>\n",
    "If, for example, you want to retrieve the first 10 rows, you can use it as follows `.head(n=10)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>relatedCompany</th>\n",
       "      <th>auctionStart</th>\n",
       "      <th>auctionEnd</th>\n",
       "      <th>branchCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200001</td>\n",
       "      <td>Solutions Electronic Advanced</td>\n",
       "      <td>2017-12-22 16:32:01</td>\n",
       "      <td>2018-01-10 15:02:01</td>\n",
       "      <td>transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>Design Systems Source</td>\n",
       "      <td>2017-09-20 13:50:04</td>\n",
       "      <td>2018-01-10 13:10:04</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200003</td>\n",
       "      <td>Electronic Design Internet</td>\n",
       "      <td>2018-02-01 14:09:22</td>\n",
       "      <td>2018-01-10 13:09:22</td>\n",
       "      <td>woodworking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200136</td>\n",
       "      <td>Contract Graphics Adventure</td>\n",
       "      <td>2018-05-23 16:11:20</td>\n",
       "      <td>2018-06-01 10:11:20</td>\n",
       "      <td>construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200139</td>\n",
       "      <td>Alpha Virtual</td>\n",
       "      <td>2018-02-05 12:50:01</td>\n",
       "      <td>2018-02-09 12:30:01</td>\n",
       "      <td>construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200006</td>\n",
       "      <td>Design Vision Inc</td>\n",
       "      <td>2018-01-08 08:26:09</td>\n",
       "      <td>2018-01-16 14:56:09</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200007</td>\n",
       "      <td>Hardware West Organization</td>\n",
       "      <td>2017-11-23 09:27:00</td>\n",
       "      <td>2018-01-30 13:27:00</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200008</td>\n",
       "      <td>Telecom Adventure Power Limited</td>\n",
       "      <td>2017-11-23 09:29:22</td>\n",
       "      <td>2018-01-30 13:29:22</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200009</td>\n",
       "      <td>South Adventure Contract</td>\n",
       "      <td>2017-10-27 22:01:30</td>\n",
       "      <td>2018-01-23 15:01:30</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200010</td>\n",
       "      <td>Signal Interactive</td>\n",
       "      <td>2017-12-15 15:19:30</td>\n",
       "      <td>2018-01-03 19:19:30</td>\n",
       "      <td>construction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                   relatedCompany         auctionStart  \\\n",
       "0  200001    Solutions Electronic Advanced  2017-12-22 16:32:01   \n",
       "1  200002            Design Systems Source  2017-09-20 13:50:04   \n",
       "2  200003       Electronic Design Internet  2018-02-01 14:09:22   \n",
       "3  200136      Contract Graphics Adventure  2018-05-23 16:11:20   \n",
       "4  200139                    Alpha Virtual  2018-02-05 12:50:01   \n",
       "5  200006                Design Vision Inc  2018-01-08 08:26:09   \n",
       "6  200007       Hardware West Organization  2017-11-23 09:27:00   \n",
       "7  200008  Telecom Adventure Power Limited  2017-11-23 09:29:22   \n",
       "8  200009         South Adventure Contract  2017-10-27 22:01:30   \n",
       "9  200010               Signal Interactive  2017-12-15 15:19:30   \n",
       "\n",
       "            auctionEnd branchCategory  \n",
       "0  2018-01-10 15:02:01      transport  \n",
       "1  2018-01-10 13:10:04          metal  \n",
       "2  2018-01-10 13:09:22    woodworking  \n",
       "3  2018-06-01 10:11:20   construction  \n",
       "4  2018-02-09 12:30:01   construction  \n",
       "5  2018-01-16 14:56:09          other  \n",
       "6  2018-01-30 13:27:00          other  \n",
       "7  2018-01-30 13:29:22          other  \n",
       "8  2018-01-23 15:01:30    real estate  \n",
       "9  2018-01-03 19:19:30   construction  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Print and investigate the first 10 rows of the auctions dataframe.\n",
    "auctions.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countryCode</th>\n",
       "      <th>saleDate</th>\n",
       "      <th>auctionID</th>\n",
       "      <th>lotNr</th>\n",
       "      <th>suffix</th>\n",
       "      <th>numberOfItems</th>\n",
       "      <th>buyerAccountID</th>\n",
       "      <th>estimatedValue</th>\n",
       "      <th>startingBid</th>\n",
       "      <th>reserveBid</th>\n",
       "      <th>currentBid</th>\n",
       "      <th>vat</th>\n",
       "      <th>category</th>\n",
       "      <th>sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Available</td>\n",
       "      <td>2018-01-02 14:22:29</td>\n",
       "      <td>200013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Rolling Material</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Available</td>\n",
       "      <td>2018-01-02 14:22:29</td>\n",
       "      <td>200013.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3125554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Rolling Material</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Available</td>\n",
       "      <td>2018-01-02 14:22:29</td>\n",
       "      <td>200013.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Rolling Material</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Available</td>\n",
       "      <td>2018-01-02 14:22:29</td>\n",
       "      <td>200013.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Rolling Material</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Available</td>\n",
       "      <td>2018-01-02 14:22:29</td>\n",
       "      <td>200013.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>66.0</td>\n",
       "      <td>99999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Furniture and Accessories</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     countryCode             saleDate  auctionID  lotNr         suffix  \\\n",
       "0  Not Available  2018-01-02 14:22:29   200013.0    1.0  Not Available   \n",
       "1  Not Available  2018-01-02 14:22:29   200013.0    2.0  Not Available   \n",
       "2  Not Available  2018-01-02 14:22:29   200013.0    3.0  Not Available   \n",
       "3  Not Available  2018-01-02 14:22:29   200013.0    4.0  Not Available   \n",
       "4  Not Available  2018-01-02 14:22:29   200013.0    5.0  Not Available   \n",
       "\n",
       "   numberOfItems  buyerAccountID  estimatedValue  startingBid  reserveBid  \\\n",
       "0            1.0         99999.0             0.0         10.0         1.0   \n",
       "1            1.0       3125554.0             0.0         25.0         1.0   \n",
       "2            1.0         99999.0             0.0         25.0         1.0   \n",
       "3            1.0         99999.0             0.0         25.0         1.0   \n",
       "4           66.0         99999.0             0.0         10.0         1.0   \n",
       "\n",
       "   currentBid   vat                   category  sold  \n",
       "0       160.0  21.0           Rolling Material   0.0  \n",
       "1        25.0  21.0           Rolling Material   1.0  \n",
       "2        25.0  21.0           Rolling Material   0.0  \n",
       "3       160.0  21.0           Rolling Material   0.0  \n",
       "4        55.0  21.0  Furniture and Accessories   0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Print and investigate the first x rows of the lots dataframe.\n",
    "lots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auctionID</th>\n",
       "      <th>LotNr</th>\n",
       "      <th>bidNr</th>\n",
       "      <th>LotID</th>\n",
       "      <th>IsCombination</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>IsCompany</th>\n",
       "      <th>BidPrice</th>\n",
       "      <th>BiddingDateTime</th>\n",
       "      <th>ClosingDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4705593.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3094282</td>\n",
       "      <td>1</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>2017-12-23 08:52:28</td>\n",
       "      <td>2018-01-10 14:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4705593.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2930599</td>\n",
       "      <td>1</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>2017-12-30 16:05:36</td>\n",
       "      <td>2018-01-10 14:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4705593.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2851482</td>\n",
       "      <td>1</td>\n",
       "      <td>18500.0</td>\n",
       "      <td>2017-12-31 16:02:21</td>\n",
       "      <td>2018-01-10 14:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4705593.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2930599</td>\n",
       "      <td>1</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>2018-01-03 15:52:04</td>\n",
       "      <td>2018-01-10 14:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200001</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4705593.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2851482</td>\n",
       "      <td>1</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>2018-01-03 20:21:57</td>\n",
       "      <td>2018-01-10 14:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   auctionID  LotNr  bidNr      LotID  IsCombination  AccountID  IsCompany  \\\n",
       "0     200001      1      1  4705593.0              0    3094282          1   \n",
       "1     200001      1      2  4705593.0              0    2930599          1   \n",
       "2     200001      1      3  4705593.0              0    2851482          1   \n",
       "3     200001      1      4  4705593.0              0    2930599          1   \n",
       "4     200001      1      5  4705593.0              0    2851482          1   \n",
       "\n",
       "   BidPrice      BiddingDateTime      ClosingDateTime  \n",
       "0   17500.0  2017-12-23 08:52:28  2018-01-10 14:35:00  \n",
       "1   18000.0  2017-12-30 16:05:36  2018-01-10 14:35:00  \n",
       "2   18500.0  2017-12-31 16:02:21  2018-01-10 14:35:00  \n",
       "3   19000.0  2018-01-03 15:52:04  2018-01-10 14:35:00  \n",
       "4   19500.0  2018-01-03 20:21:57  2018-01-10 14:35:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Print and investigate the first x rows of the bids dataframe.\n",
    "bids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions B2\n",
    "* `Q_B2_0` - What is the name of the company with `woodworking` assigned as `branchCategory`, based on the top 10 rows from `auctions` dataframe? <br>\n",
    "* `Q_B2_1` - What is the value for `CurrentBid` of the lot on row index 4, from the `lots` data frame? <br>\n",
    "* `Q_B2_2` - What is the `bidPrice` for the with `AccountID` equal to `3094282` looking at the top 5 rows from the `bids` data frame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游릭 That's correct!          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Electronic Design Internet'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What is the name of the company with woodworking assigned as branchCategory, based on the top 10 rows from auctions daframe?\n",
    "Q_B2_0 = 'Electronic Design Internet' \n",
    "\n",
    "module.check(\"B2_0\", Q_B2_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游릭 That's correct!         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What is the value for CurrentBid of the lot on row index 4, from the lots data frame?\n",
    "Q_B2_1 = 55\n",
    "module.check(\"B2_1\", Q_B2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游릭 That's correct!         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17500.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What is the bidPrice for the with AccountID equal to 3094282 looking at the top 5 rows from the bids data frame?\n",
    "Q_B2_2 = 17500.0\n",
    "\n",
    "module.check(\"B2_2\", Q_B2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3. Missing Values\n",
    "Look for missing (<i>null</i>) values in the data using the `.info(show_counts=True)` command on the Pandas Dataframes. <br>\n",
    "Based on the gained insights, answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1556 entries, 0 to 1555\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              1556 non-null   int64 \n",
      " 1   relatedCompany  1556 non-null   object\n",
      " 2   auctionStart    1556 non-null   object\n",
      " 3   auctionEnd      1556 non-null   object\n",
      " 4   branchCategory  1556 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 60.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#TODO: Print the information of the auctions dataframe\n",
    "auctions.info(show_counts=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 285307 entries, 0 to 285306\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   countryCode     285307 non-null  object \n",
      " 1   saleDate        285307 non-null  object \n",
      " 2   auctionID       285307 non-null  float64\n",
      " 3   lotNr           285307 non-null  float64\n",
      " 4   suffix          285307 non-null  object \n",
      " 5   numberOfItems   285307 non-null  float64\n",
      " 6   buyerAccountID  285307 non-null  float64\n",
      " 7   estimatedValue  285307 non-null  float64\n",
      " 8   startingBid     285307 non-null  float64\n",
      " 9   reserveBid      285307 non-null  float64\n",
      " 10  currentBid      285307 non-null  float64\n",
      " 11  vat             285307 non-null  float64\n",
      " 12  category        284646 non-null  object \n",
      " 13  sold            285307 non-null  float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 30.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#TODO: Print the information of the lots dataframe\n",
    "lots.info(show_counts=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3178996 entries, 0 to 3178995\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   auctionID        3178996 non-null  int64  \n",
      " 1   LotNr            3178996 non-null  int64  \n",
      " 2   bidNr            3178996 non-null  int64  \n",
      " 3   LotID            3178996 non-null  float64\n",
      " 4   IsCombination    3178996 non-null  int64  \n",
      " 5   AccountID        3178996 non-null  int64  \n",
      " 6   IsCompany        3178996 non-null  int64  \n",
      " 7   BidPrice         3178996 non-null  float64\n",
      " 8   BiddingDateTime  3178996 non-null  object \n",
      " 9   ClosingDateTime  3178996 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 242.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#TODO: Print the information of the bids dataframe\n",
    "bids.info(show_counts=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions B3\n",
    "* `Q_B3_0` - How many null values does the `auctions` dataframe contain? <br>\n",
    "* `Q_B3_1` - Only the column `numberOfItems` has null values in the `lots` dataframe, `True` or `False`? <br>\n",
    "* `Q_B3_2` - The Bids dataframe has null values in all columns, `True` or `False`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游릭 That's correct!         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q_B3_0 = 0\n",
    "module.check(\"B3_0\", Q_B3_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游릭 That's correct!         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q_B3_1 = False\n",
    "module.check(\"B3_1\", Q_B3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游릭 That's correct!         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q_B3_2 = False\n",
    "module.check(\"B3_2\", Q_B3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4. Outliers\n",
    "Look for potential `outliers` in the numerical values using the `.describe()` command on the Pandas Dataframes. <br>\n",
    "Based on the gained knowledge from exercising this function, answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1556.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>203384.173522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4409.692815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>200398.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200783.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>210066.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>210455.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id\n",
       "count    1556.000000\n",
       "mean   203384.173522\n",
       "std      4409.692815\n",
       "min    200001.000000\n",
       "25%    200398.750000\n",
       "50%    200783.500000\n",
       "75%    210066.250000\n",
       "max    210455.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Print the description of the numerical values of the auctions Pandas Dataframe.\n",
    "auctions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auctionID</th>\n",
       "      <th>lotNr</th>\n",
       "      <th>numberOfItems</th>\n",
       "      <th>buyerAccountID</th>\n",
       "      <th>estimatedValue</th>\n",
       "      <th>startingBid</th>\n",
       "      <th>reserveBid</th>\n",
       "      <th>currentBid</th>\n",
       "      <th>vat</th>\n",
       "      <th>sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>285307.000000</td>\n",
       "      <td>285307.000000</td>\n",
       "      <td>285307.000000</td>\n",
       "      <td>2.853070e+05</td>\n",
       "      <td>2.853070e+05</td>\n",
       "      <td>2.853070e+05</td>\n",
       "      <td>285307.000000</td>\n",
       "      <td>2.853070e+05</td>\n",
       "      <td>285307.000000</td>\n",
       "      <td>285307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>205292.621492</td>\n",
       "      <td>706.946868</td>\n",
       "      <td>15.461037</td>\n",
       "      <td>2.179230e+06</td>\n",
       "      <td>3.951862e+02</td>\n",
       "      <td>1.306506e+02</td>\n",
       "      <td>1.206276</td>\n",
       "      <td>4.045803e+02</td>\n",
       "      <td>19.681168</td>\n",
       "      <td>0.817383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4884.057343</td>\n",
       "      <td>1046.480555</td>\n",
       "      <td>693.356570</td>\n",
       "      <td>1.348148e+06</td>\n",
       "      <td>4.520164e+03</td>\n",
       "      <td>2.878194e+03</td>\n",
       "      <td>35.009842</td>\n",
       "      <td>4.434069e+03</td>\n",
       "      <td>4.928022</td>\n",
       "      <td>0.386353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999900e+04</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.508000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>200420.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999900e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>201074.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.943484e+06</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>210201.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.169882e+06</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.510000e+02</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>210455.000000</td>\n",
       "      <td>9618.000000</td>\n",
       "      <td>312000.000000</td>\n",
       "      <td>3.338731e+06</td>\n",
       "      <td>1.300000e+06</td>\n",
       "      <td>1.300000e+06</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.600000e+06</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           auctionID          lotNr  numberOfItems  buyerAccountID  \\\n",
       "count  285307.000000  285307.000000  285307.000000    2.853070e+05   \n",
       "mean   205292.621492     706.946868      15.461037    2.179230e+06   \n",
       "std      4884.057343    1046.480555     693.356570    1.348148e+06   \n",
       "min    200001.000000       0.000000       1.000000    9.999900e+04   \n",
       "25%    200420.000000     120.000000       1.000000    9.999900e+04   \n",
       "50%    201074.000000     308.000000       1.000000    2.943484e+06   \n",
       "75%    210201.000000     738.000000       2.000000    3.169882e+06   \n",
       "max    210455.000000    9618.000000  312000.000000    3.338731e+06   \n",
       "\n",
       "       estimatedValue   startingBid     reserveBid    currentBid  \\\n",
       "count    2.853070e+05  2.853070e+05  285307.000000  2.853070e+05   \n",
       "mean     3.951862e+02  1.306506e+02       1.206276  4.045803e+02   \n",
       "std      4.520164e+03  2.878194e+03      35.009842  4.434069e+03   \n",
       "min     -1.000000e+00  0.000000e+00       0.000000 -1.508000e+02   \n",
       "25%      0.000000e+00  1.000000e+01       1.000000  1.500000e+01   \n",
       "50%      2.000000e+01  1.000000e+01       1.000000  4.500000e+01   \n",
       "75%      1.000000e+02  5.000000e+01       1.000000  1.510000e+02   \n",
       "max      1.300000e+06  1.300000e+06   10000.000000  1.600000e+06   \n",
       "\n",
       "                 vat           sold  \n",
       "count  285307.000000  285307.000000  \n",
       "mean       19.681168       0.817383  \n",
       "std         4.928022       0.386353  \n",
       "min         0.000000       0.000000  \n",
       "25%        21.000000       1.000000  \n",
       "50%        21.000000       1.000000  \n",
       "75%        21.000000       1.000000  \n",
       "max        22.000000       1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Print the description of the numerical values of the lots Pandas Dataframe.\n",
    "lots.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auctionID</th>\n",
       "      <th>LotNr</th>\n",
       "      <th>bidNr</th>\n",
       "      <th>LotID</th>\n",
       "      <th>IsCombination</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>IsCompany</th>\n",
       "      <th>BidPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.178996e+06</td>\n",
       "      <td>3.178996e+06</td>\n",
       "      <td>3.178996e+06</td>\n",
       "      <td>3.178996e+06</td>\n",
       "      <td>3.178996e+06</td>\n",
       "      <td>3.178996e+06</td>\n",
       "      <td>3.178996e+06</td>\n",
       "      <td>3.178996e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.066205e+05</td>\n",
       "      <td>4.550741e+02</td>\n",
       "      <td>1.572412e+01</td>\n",
       "      <td>5.294385e+06</td>\n",
       "      <td>6.826055e-05</td>\n",
       "      <td>3.030902e+06</td>\n",
       "      <td>6.622320e-01</td>\n",
       "      <td>7.655975e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.698346e+03</td>\n",
       "      <td>8.245781e+02</td>\n",
       "      <td>1.596777e+01</td>\n",
       "      <td>3.487074e+05</td>\n",
       "      <td>8.261713e-03</td>\n",
       "      <td>2.239804e+05</td>\n",
       "      <td>4.729491e-01</td>\n",
       "      <td>3.756768e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000010e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.636761e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.505522e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.006520e+05</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.929955e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.883948e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.100710e+05</td>\n",
       "      <td>1.640000e+02</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>5.435180e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.108859e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.200000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.102380e+05</td>\n",
       "      <td>4.320000e+02</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>5.583198e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.195484e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.104550e+05</td>\n",
       "      <td>9.618000e+03</td>\n",
       "      <td>2.160000e+02</td>\n",
       "      <td>5.769222e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.338731e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.600000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          auctionID         LotNr         bidNr         LotID  IsCombination  \\\n",
       "count  3.178996e+06  3.178996e+06  3.178996e+06  3.178996e+06   3.178996e+06   \n",
       "mean   2.066205e+05  4.550741e+02  1.572412e+01  5.294385e+06   6.826055e-05   \n",
       "std    4.698346e+03  8.245781e+02  1.596777e+01  3.487074e+05   8.261713e-03   \n",
       "min    2.000010e+05  0.000000e+00  1.000000e+00  4.636761e+06   0.000000e+00   \n",
       "25%    2.006520e+05  5.400000e+01  4.000000e+00  4.929955e+06   0.000000e+00   \n",
       "50%    2.100710e+05  1.640000e+02  1.100000e+01  5.435180e+06   0.000000e+00   \n",
       "75%    2.102380e+05  4.320000e+02  2.200000e+01  5.583198e+06   0.000000e+00   \n",
       "max    2.104550e+05  9.618000e+03  2.160000e+02  5.769222e+06   1.000000e+00   \n",
       "\n",
       "          AccountID     IsCompany      BidPrice  \n",
       "count  3.178996e+06  3.178996e+06  3.178996e+06  \n",
       "mean   3.030902e+06  6.622320e-01  7.655975e+02  \n",
       "std    2.239804e+05  4.729491e-01  3.756768e+03  \n",
       "min    2.505522e+06  0.000000e+00  1.000000e+00  \n",
       "25%    2.883948e+06  0.000000e+00  4.000000e+01  \n",
       "50%    3.108859e+06  1.000000e+00  1.200000e+02  \n",
       "75%    3.195484e+06  1.000000e+00  3.500000e+02  \n",
       "max    3.338731e+06  1.000000e+00  1.600000e+06  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Print the description of the numerical values of the bids Pandas Dataframe.\n",
    "bids.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions B4\n",
    "* `Q_B4_0` - What is the max `id` for the `auctions` dataframe? <br>\n",
    "* `Q_B4_1` - What is the maximal value for `numberOfItems` in the `lots` dataframe? <br>\n",
    "* `Q_B4_2` - What is the mean value for `BidPrice` in the `bids` dataframe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游릭 That's correct!         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "210455.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q_B4_0 = 210455.0\n",
    "module.check(\"B4_0\", Q_B4_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游릭 That's correct!         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "312000.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q_B4_1 = 312000.0\n",
    "module.check(\"B4_1\", Q_B4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游릭 That's correct!         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3178996.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q_B4_2 = 3178996.0\n",
    "module.check(\"B4_2\", Q_B4_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B5. Analyze categories\n",
    "Investigate the occurrence of different categories in the column `branchCategory` of the `auction` dataframe. <br>\n",
    "To do this, you will need the `Counter` function, imported from the `Collections` library. <br>\n",
    "We suggest to take a look at the documentation, which can be found by clicking <a href=\"https://docs.python.org/3/library/collections.html#collections.Counter\">here</a>. <br>\n",
    "When successfully obtained the number of occurrences per category, send this in form of a dictionary to the checker function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游릭 That's correct!         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'transport': 202,\n",
       " 'metal': 202,\n",
       " 'woodworking': 68,\n",
       " 'construction': 142,\n",
       " 'other': 213,\n",
       " 'real estate': 40,\n",
       " 'agricultural': 113,\n",
       " 'consumer': 283,\n",
       " 'food': 208,\n",
       " 'graphical': 27,\n",
       " 'plastic': 10,\n",
       " 'pharmaceutical': 48}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: Retrieve the number of occurrences for all branch categories of the auctions dataframe.\n",
    "totalByCategory = Counter(auctions.branchCategory)\n",
    "\n",
    "#TODO: Place the values in a dictionary and send it to the checker function.\n",
    "Q_B5 = dict(totalByCategory)\n",
    "module.check(\"B5\", Q_B5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## C. Preprocessing and storing\n",
    "\n",
    "The initial analysis of the raw data consisted of the descriptive analysis. Now, the invention provides a method for preprocessing and storing data, which relates to the technical field of data storage and comprises the following steps: <br>\n",
    "\n",
    "* `Preprocessing` - Transform the raw data in an usefull and efficient format.\n",
    "* `Storage` - Setup a SQL database.\n",
    "* `Acquire data` - Retrieve the preprocessed data.\n",
    "* `Transmitting` - Fill the database with the data.\n",
    "* `Enhance` - Improve data consistency and quality for rigorous data management.\n",
    "\n",
    "Creation and usage of the `MySQL` database is similar to the way we used it in the `API Advanced` module. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h5> C1: Preprocessing raw the data </h5>\n",
    "<p>\n",
    "In this subcomponent some of the code is already given, however additional functionality is required to make the framework more robust. <br>\n",
    "To guide you through the process a list of consecutive actions is shown below:\n",
    "<ol>\n",
    "    <li> <u><b>Data types:</b></u> Selecting a new data type corresponding to the column. </li>\n",
    "    <li> <u><b>Outlier handling:</b></u> Remove or transform outliers in the dataset. </li>\n",
    "    <li> <u><b>Missing values:</b></u> Manage your data with missing data in the dataset. </li>\n",
    "    <li> <u><b>Remove duplicate values:</b></u> Creates consistent data in the dataset. </li>\n",
    "</ol>\n",
    "As mentioned before mostly any further steps of the data preprocessing steps depends on the next steps. <br>\n",
    "For example, Feature Engineering and Scaling the data is dependent on the method. Since e.g., you do not want any scaled pricing data in you dashboard, you want actual money. <br>\n",
    "<br>\n",
    "We first start with correcting all the Data Type inconsistencies. Some conficts may occur when we want to create relational databases. <br>\n",
    "As you might have noticed the related columns: <code>id</code> in <code>auctions</code> <--> <code>auctionID</code> in <code>lots</code>; and <code>lotNr</code> in <code>lots</code> <--> <code>LotNr</code> in <code>bids</code> have different data types. <br>\n",
    "Not only these columns but also the columns: <code>numberOfItems</code> and <code>buyerAccountID</code> in <code>lots</code>; <code>LotID</code> in <code>bids</code> have incorrect dtypes.<br>\n",
    "<br>\n",
    "<l>\n",
    "    <li> <u><b>Objective 1:</b></u> Transform all these inconsistent dtypes to integers. </li>\n",
    "</l>\n",
    "<br>\n",
    "We also observe that the dates are all seen as objects and not as datetimes. Transform the following datetimes: <code>auctionStart</code> and <code>auctionEnd</code> in <code>auctions</code>; <code>saleDate</code> in <code>lots</code>; <code>BiddingDateTime</code> and <code>ClosingDateTime</code> in <code>bids</code>.<br>\n",
    "<br>\n",
    "<l>\n",
    "    <li> <u><b>Objective 2:</b></u> Transform all these inconsistent dtypes to datetimes. </li>\n",
    "</l>\n",
    "<br>\n",
    "And finally we want to transform the columns: <code>sold</code> in <code>lots</code> and <code>IsCombination</code> and <code>IsCompany</code> in <code>bids</code> to a boolean to make it make obvious. <br>\n",
    "<l>\n",
    "    <li> <u><b>Objective 3:</b></u> Transform the final inconsistent dtypes to a Boolean. </li>\n",
    "</l>\n",
    "<br>\n",
    "The database we are using (SQLite) does not have a storage class set aside for storing dates and/or times. <br>\n",
    "Instead, the built-in Date And Time Functions of SQLite are capable of storing dates and times as TEXT values. <br>\n",
    "We therefore have to transform these values if we want to work with them.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms each column to the correct dtype\n",
    "\n",
    "# Transforms each column to the correct dtype\n",
    "dtype_dic = {\n",
    "    \"integer\" : {\n",
    "        'lots': ['auctionID', 'lotNr', 'numberOfItems', 'buyerAccountID'],\n",
    "        'bids': ['LotID']\n",
    "                }, \n",
    "    \"datetime\": {\n",
    "        'auctions': ['auctionStart', 'auctionEnd'],\n",
    "        'lots': ['saleDate'],\n",
    "        'bids': ['BiddingDateTime', 'ClosingDateTime']\n",
    "                },\n",
    "    \"boolean\": {\n",
    "            'lots': ['sold'],\n",
    "            'bids': ['IsCombination', 'IsCompany']\n",
    "               }\n",
    "            }\n",
    "\n",
    "for keys_dtype in dtype_dic:\n",
    "    for keys_df in dtype_dic[keys_dtype]:\n",
    "        for column_name in dtype_dic[keys_dtype][keys_df]:\n",
    "            \n",
    "            if keys_dtype == 'integer':\n",
    "                if keys_df == 'auctions':\n",
    "                    auctions[column_name] = auctions[column_name].astype(int)\n",
    "                elif keys_df == 'lots':\n",
    "                    lots[column_name] = lots[column_name].astype(int)\n",
    "                elif keys_df == 'bids':\n",
    "                    bids[column_name] = bids[column_name].astype(int)\n",
    "\n",
    "            elif keys_dtype == 'datetime':\n",
    "                if keys_df == 'auctions':\n",
    "                    auctions[column_name] = pd.to_datetime(auctions[column_name], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "                elif keys_df == 'lots':\n",
    "                    lots[column_name] = pd.to_datetime(lots[column_name], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "                elif keys_df == 'bids':\n",
    "                    bids[column_name] = pd.to_datetime(bids[column_name], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "            \n",
    "            elif keys_dtype == 'boolean':\n",
    "                if keys_df == 'lots':\n",
    "                    lots[column_name] = lots[column_name].astype(bool)\n",
    "                elif keys_df == 'bids':\n",
    "                    bids[column_name] = bids[column_name].astype(bool)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start with looking for actual outliers. We assume and see in our descriptive analysis that there are not any inconsistancies in the auction and bids DataFrame. <br>\n",
    "However, we observe that in the lots the <code>estimatedValue</code> and <code>currentBid</code> column negative values contains. This can not be the case in real life. <br>\n",
    "To correct for this, look at the values where these negative numbers occur. Then change or remove these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h5>Questions:</h5>\n",
    "<p> \n",
    "  Q_C1:   How many lots with negative values on `currentBid`column? If there is any, remove them from the dataframe.<br>\n",
    "Q_C1_1:   How many rows with the `Category` `Unknow` in the lots dataframe?<br>\n",
    "Q_C1_2:   How many duplicates rows does auctions datafrane have?<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Print all lots with currentBid smaller than 0.\n",
    "#How many lots with negative values on `currentBid`column? If there is any, remove them from the dataframe.\n",
    "\n",
    "Q_C1_0 = 4\n",
    "module.check(\"C1_0\", Q_C1_0)\n",
    "\n",
    "lots[lots.currentBid < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These rows need to be removed because we checked and it does not match the bids in the time course, you can not say anything about it\n",
    "remove_row_ids = lots[lots.currentBid < 0].index\n",
    "\n",
    "# So these are the action rows we want to remove.\n",
    "lots.drop(remove_row_ids, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the values was deleted.\n",
    "lots[lots.estimatedValue < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one can go from -1.0 --to-> 0.0 \n",
    "lots['estimatedValue'] = lots.estimatedValue.replace({-1.0:0.0})\n",
    "# lots[lots.estimatedValue < 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we set all the data types right, we can check if there are some missing values present. <br>\n",
    "First we check each dataframe for missing values. We notice that there are only missing values in the <i>category</i> column of the <i>lots</i> DataFrame.\n",
    "<br>\n",
    "<l>\n",
    "    <li> <u><b>Objective 1:</b></u> Transform all the <code>NaN</code> values in the <i>category</i> column to <i>Unknown</i>. </li>\n",
    "</l>\n",
    "<br>\n",
    "Then we want to check if all our relations between our different data tables have corresponding values. <br>\n",
    "So for example, we only want data were there is a bid placed, this bid corresponds to a lot, and finally this lot corresponds to an auction. <br>\n",
    "It can be the case that there is some links between of these relations (bids <-> lots, lots <-> auctions) is missing. <br>\n",
    "It is therefore our job to figure out if all of these data points have linking values. <br>\n",
    "<br>\n",
    "<l>\n",
    "    <li> <u><b>Objective 2:</b></u> Check if there are some missing values in the lots <-> auctions relationship<i>*</i>. If so, remove the corresponding rows. </li>\n",
    "</l>\n",
    "<br>\n",
    "<i>*Tip: Check this with an outer join.</i> <br>\n",
    "We only do this for the lots <-> auctions relationships. Since doing this for the bids <-> lots relation results in a very inefficient computational cost. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check how many NaN does lots have\n",
    "# lots[lots.isnull().any(axis=1)]\n",
    "\n",
    "#TODO Use fill NaN to replace Nan to `Unknow`\n",
    "lots['category'] = lots['category'].fillna('Unknown')\n",
    "# lots[lots.isnull().any(axis=1)]\n",
    "\n",
    "# How many rows with the `Category` `Unknow` in the lots dataframe?\n",
    "Q_C1_1 = 66\n",
    "module.check(\"C1\", Q_C1)\n",
    "\n",
    "lots[lots['category'] == 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns the ids of the auctions which doesn't occur in the lots auctionID column.\n",
    "remove_these_ids = pd.merge(lots, auctions, left_on='auctionID', right_on='id', how='outer')[pd.merge(lots, auctions, left_on='auctionID', right_on='id', how='outer').lotNr.isna()].id.unique()\n",
    "\n",
    "# So these are the action rows we want to remove.\n",
    "auctions.drop(auctions.index[auctions['id'].isin(remove_these_ids)], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we do not want any duplicate values in our dataset. <br>\n",
    "Removing duplicate values from your data set plays an important role in the cleansing process. <br>\n",
    "Duplicate data takes up unnecessary storage space and slows down calculations at a minimum. <br>\n",
    "At worst, duplicate data can skew analysis results and threaten the integrity of the data set. <br>\n",
    "<br>\n",
    "<l>\n",
    "    <li> <u><b>Objective 1:</b></u> Remove the rows where there is a duplicate auction id in the auction dataframe. </li>\n",
    "</l>\n",
    "<br>\n",
    "<i>*Tip: Remove the latest auctionEnd time and not the earliest.</i> <br>\n",
    "You can check why we want you to do this. Because the corresponding lot ending time needs to be the same as this auction ending time. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl_df = auctions.groupby('id').filter(lambda x: len(x) > 1).sort_values('id')\n",
    "\n",
    "# How many duplicates rows does auctions datafrane have?\n",
    "Q_C1_2 = 12\n",
    "module.check(\"C1_2\", Q_C1_2)\n",
    "len(dupl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get al duplicate id and store the index of the onces you want to remove in a list\n",
    "unique_dupl_id = dupl_df.id.unique()\n",
    "index_to_drop = []\n",
    "lots.loc[(lots.auctionID == 200218)]['saleDate'].unique()\n",
    "for un_id in unique_dupl_id:\n",
    "    remove_date = dupl_df[dupl_df['id']==un_id]['auctionEnd'].max()\n",
    "    \n",
    "    index_to_drop.append(dupl_df.loc[(dupl_df.id == un_id) & (dupl_df.auctionEnd == remove_date)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list comprehension\n",
    "flat_ls = [item for sublist in index_to_drop for item in sublist]\n",
    "\n",
    "# So these are the action rows we want to remove.\n",
    "auctions.drop(flat_ls, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h5> C2: Storing the preprocessed data </h5>\n",
    "<p> \n",
    "After gaining a greater understanding of the data and creating some clustering and prediction models, it is time to put our code into production. <br>\n",
    "Before being able to do this, we first need to get our data to a database and create APIs to communicate with this database. <br>\n",
    "<br>\n",
    "\n",
    "For this assignment we will use a local mysql server, just as we learned in [<b>FastAPI with SQL - Tutorial</b>](https://www.youtube.com/watch?v=eltKL8kC160). <br>\n",
    "A lot of code is already given, however additional functionality is required to make the framework more robust. <br>\n",
    "<br>\n",
    "<l>\n",
    "    <li> <u><b>Objective 1:</b></u> Create a <code>model.py</code> file in the M10_FINAL > app folder with the correct columns and relationships. </li>\n",
    "</l>\n",
    "<br>\n",
    "Next up are the Pydantic models, which define more or less a \"schema\" (a valid data shape). This will shape our data which the API will recieve and the API will respond with. <br>\n",
    "To make thing easier, have a look back at the API - Advanced course.<br> \n",
    "<br>\n",
    "<l>\n",
    "    <li> <u><b>Objective 2:</b></u> Create the Pydantic models (or let's say \"schemas\") to have common attributes while creating or reading data. </li>\n",
    "</l>\n",
    "<br>\n",
    "Now we're go ahead a move on to creating the API and getting everything up and running. <br>\n",
    "As you may recall we use two files. The <code>main.py</code> (1.) file represents where our API lifes. <br>\n",
    "And the <code>services.py</code> (2.) file can be seen as the middle man between the API and the database. <br>\n",
    "<br>\n",
    "<l>\n",
    "    <li> <u><b>Objective 3:</b></u> Create the <code>main.py</code> and <code>services.py</code> files (similar as in the <b>API - Advanced course</b>: <i>API - DataBase setup</i> in \"main.py and services.py for users\"). </li>\n",
    "</l>\n",
    "<br>\n",
    "Since most of the work is now set and done, we can start the API and create a database:\n",
    "<ol>\n",
    "    <li> Open the Anaconda Prompt (anaconda3), <i>do not forget to activate the environment</i>; </li>\n",
    "    <li> Navigate to your locally stored folder M10_Final; </li>\n",
    "    <li> Load the fastapi connections and create an empty database using the command: <code>uvicorn app.main:app --reload</code>; </li>\n",
    "    <li> Open the url on which Uvicorn is running and append <b>/docs</b> to the end, for example: <i>\"http://127.0.0.1:8000/docs\"</i>\n",
    "</ol>\n",
    "If it is working correctly a new database.db will appear in the M10_FINAL > src folder. Your task is now to fill you database you have created. <br>\n",
    "We already proved the code for you to fill you database. To do so: <br>\n",
    "<br>\n",
    "<l>\n",
    "    <li> <u><b>Objective 4:</b></u> Send our cleaned DataFrames to the database by running the code* below. </li>\n",
    "</l>\n",
    "<br>\n",
    "<i>*Note 1: This uploadData function replaces all the data currently in your database. It does NOT append data to it.</i> <br>\n",
    "<i>*Note 2: This uploadData function might take some time since it has quite some data to store.</i> <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.uploadData import uploadData  \n",
    "    \n",
    "df_to_upload = {\n",
    "    'auctions': auctions,\n",
    "    'lots': lots,\n",
    "    'bids': bids\n",
    "    }\n",
    "_ = uploadData(dic_dfs=df_to_upload)      \n",
    "                                      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an extra assignment, we can also perform some SQL queries over our stored data.  <br>\n",
    "It is a reliable and efficient language used for communicating with the database. <br>\n",
    "Some advantages of SQL are as follows: <br>\n",
    "<ol>\n",
    "    <li> Large amount of data is retrieved quickly and efficiently; </li>\n",
    "    <li> For data retrieval, large number of lines of code is not required; </li>\n",
    "    <li> And it is relatively easy to learn and understand. </i>\n",
    "</ol>\n",
    "We use the Python <code>SQLite3</code> module to integrate the SQLite database with Python. <br>\n",
    "It is a pretty straightforward and simple-to-use library for interacting with SQLite databases. <br>\n",
    "There is no need to install this module separately as it comes along with Python after the 2.5x version.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(f\"./database.db\")\n",
    "cur = conn.cursor()\n",
    "sql_query = \"\"\"\n",
    "            SELECT * \n",
    "            FROM 'lots'\n",
    "            LIMIT 0,1\n",
    "            \"\"\"\n",
    "display(cur.execute(sql_query).fetchall())\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>\n",
    "<h3> D: Cluster bidding behavior </h3>\n",
    "<p>\n",
    "The initial analysis of the data will consists of clustering of bidding behavior. <br>\n",
    "By clustering the behavior we gain insight into what bidding strategies there are amongst different bidders. <br>\n",
    "Besides being of big descriptive value, these clusters can also be used in further programming like a prediction model. <br>\n",
    "The expected composition of different bidder behaviors can for example be of determinative value for the outcome of the auction. <br>\n",
    "\n",
    "In this module you will implement the KMeans algorithm to classify certain bidders into different categories of behavior. <br>\n",
    "To guide you through the process a list of consecutive actions is shown below:\n",
    "<ol>\n",
    "    <li> <u><b>Feature Engineering:</b></u> Extract useful characteristics from the dataset. </li>\n",
    "    <li> <u><b>Scale the data:</b></u> Apply scaling to all numeric values. </li>\n",
    "    <li> <u><b>Find number of clusters:</b></u> Use the elbow method in the pre-written code below to find the optimal number of clusters. </li>\n",
    "    <li> <u><b>Cluster the data:</b></u> Using the found optimal number of clusters, cluster the entire dataset. </li>\n",
    "    <li> <u><b>Extract cluster characteristics:</b></u> Retrieve the average values of all parameters per cluster. </li>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Notice that we need to query data from database tables in almost all web apps. <br>\n",
    "So, let's begin to create function that can create a Pandas DataFrame for our database tables given a query.\n",
    "<br>\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_df_from_database(table:str=None, query:str=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loading data from an SQLite database table into a Python Pandas Data Frame.\n",
    "\n",
    "    Args:\n",
    "        path_db (str): The path to the folder where the database is stored;\n",
    "        table (str): If we only want to retrieve one table, the table name is needed;\n",
    "        query (str): Write a custom query to fetch.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe retrieve from the database.\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect to the SQLite database using the line:\n",
    "    conn = sqlite3.connect((f\"database.db\"))\n",
    "\n",
    "    # Use table or query (if both are provided use table)\n",
    "    if table:\n",
    "        query_db = f\"SELECT * FROM {table};\"\n",
    "    elif query:\n",
    "        query_db = query\n",
    "    else:\n",
    "        print(\"No input is given\")\n",
    "\n",
    "    # The line that converts SQLite data to a Panda data frame is:\n",
    "    database_table = pd.read_sql_query(query_db, conn)\n",
    "    conn.close()\n",
    "\n",
    "    return database_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h5> D1: Feature Engineering </h5>\n",
    "<p>\n",
    "First we will extract some statistics about different bidders within an auction. <br>\n",
    "To do this, some characteristics of the lots are needed as well, which are:\n",
    "<ol>\n",
    "    <li> <b>FirstBid:</b> Datetime object describing the moment the first bid is placed. </li>\n",
    "    <li> <b>Duration:</b> Datetime object describing the duration of the lot (time between first and last bid). </li>\n",
    "</ol>\n",
    "These values are given through calling the function <code>generate_lot_statistic(data=bids)</code> given below. <br>\n",
    "Integrate this function within the second function: <code>generate_bid_statistic(data)</code>, which is left incomplete. <br>\n",
    "Follow the description in the DOCSTRING, which tells what the function needs to do, what it gets as input and what the output should look like. <br>\n",
    "<br>\n",
    "<i>*Note: generating bid statistics might take a while because there are a lot of computions and the size is quite big.</i> <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lot_statistic(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate statistics regarding the Lots, describing both the datetime of the fist bid and the actual duration of the lot.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Bids data, describing the bids that are made on specific auction-lot combinations.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe containing the lot statistics. This needs to contain two columns:\n",
    "            - FirstBid: The datetime of the first bid placed in the lot.\n",
    "            - Duration: The time between the first bid and the scheduled time the lot is supposed to end.\n",
    "    \"\"\"\n",
    "                \n",
    "    # Group based on SaleID and LotNumber and generate characteristics\n",
    "    lot_statistic = data.groupby(['auctionID','LotNr']).agg({'BiddingDateTime': ['min'], \n",
    "                                                             'ClosingDateTime': ['max']})\n",
    "    lot_statistic.columns = ['FirstBid', 'LotEnding']\n",
    "    \n",
    "    # Convert LotEnding (Str) to timestamp object\n",
    "    lot_statistic['LotEnding'] = lot_statistic['LotEnding'].apply(pd.to_datetime, errors='coerce')\n",
    "    \n",
    "    # Calculate Lot Duration by subtracting datetime of the first bid from the lot ending datetime\n",
    "    lot_statistic['Duration'] = lot_statistic['LotEnding'] - lot_statistic['FirstBid']\n",
    "    lot_statistic['Duration'] = lot_statistic['Duration'].apply(lambda x: x/pd.Timedelta('1 minute'))\n",
    "    lot_statistic = lot_statistic.reset_index()\n",
    "    \n",
    "    return lot_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bid_statistic(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate statistics regarding the bidders, to be used to cluster different bidding behaviors.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Bids data, describing the bids that are made on specific auction-lot combinations.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe containing the statistics regarding bidders. This needs to contain nine columns:\n",
    "            - AuctionID: The ID reference of the auction in which the bid was placed.\n",
    "            - LotNr: The number reference of the lot in which the bid was placed.\n",
    "            - AccountID: The ID reference of the bidder which placed the bid.\n",
    "            - NOB: The Number Of Bids this bidders has placed in the concerning auction lot.\n",
    "            - ABP: The Average Bid Price of all the bids that the bidders has placed in the concerning auction lot.\n",
    "            - HBP: The Highest Bid Price of all the bids that the bidders has placed in the concerning auction lot.\n",
    "            - TOE: The Time Of Entry, describing at what percentage of total lot duration the bidder placed his first bid.\n",
    "            - TOX: The Time Of Exit, describing at what percentage of total lot duration the bidder placed his last bid.\n",
    "    \"\"\"\n",
    "    # Ensure datetime type in datetime variables\n",
    "    data['BiddingDateTime'] = pd.to_datetime(data['BiddingDateTime'], format='ISO8601')\n",
    "    data['ClosingDateTime'] = pd.to_datetime(data['ClosingDateTime'], format='ISO8601')\n",
    "\n",
    "    # Group based on accountID, LotNr and AccountID and generate NOB, ABP, HBP, TOE and TOX.\n",
    "    bid_statistic = data.groupby(['auctionID','LotNr','AccountID']).agg({'BidPrice': ['count', 'mean', 'max'], \n",
    "                                                                         'BiddingDateTime': ['min', 'max']})\n",
    "    bid_statistic.columns = ['NOB', 'ABP', 'HBP', 'TOE', 'TOX']\n",
    "    bid_statistic = bid_statistic.reset_index()\n",
    "\n",
    "    # Generate statistics of the lot and merge with bid statistic\n",
    "    lot_statistic = generate_lot_statistic(data)\n",
    "    bid_statistic = pd.merge(bid_statistic, lot_statistic, on=['auctionID', 'LotNr'], how='left')\n",
    "\n",
    "    # Convert static time characteristics (TOE and TOX) to relative time characteristics using the merged Lot statistics (FirstBid and Duration)\n",
    "    bid_statistic['TOE'] = (bid_statistic['TOE'] - bid_statistic['FirstBid']).apply(lambda x: x/pd.Timedelta('1 minute'))\n",
    "    bid_statistic['TOE'] = bid_statistic['TOE'] / bid_statistic['Duration']\n",
    "    bid_statistic['TOX'] = (bid_statistic['TOX'] - bid_statistic['FirstBid']).apply(lambda x: x/pd.Timedelta('1 minute'))\n",
    "    bid_statistic['TOX'] = bid_statistic['TOX'] / bid_statistic['Duration']\n",
    "    \n",
    "    # Set outliers in normalized TOE or TOX (> 1) to 1\n",
    "    bid_statistic['TOE'] = [x if x <= 1 else 1 for x in bid_statistic['TOE']]\n",
    "    bid_statistic['TOX'] = [x if x <= 1 else 1 for x in bid_statistic['TOX']]\n",
    "\n",
    "    # Remove lot statistics from the data again\n",
    "    bid_statistic.drop(['FirstBid', 'LotEnding'], axis=1, inplace=True)\n",
    "\n",
    "    return bid_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data from the database\n",
    "bids_from_db = pandas_df_from_database(table='bids')\n",
    "bids_from_db\n",
    "# Create the bid statistic file\n",
    "bid_statistic = create_bid_statistic(data=bids_from_db)\n",
    "#bid_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_statistic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> --- D2: Scale the data --- </h4>\n",
    "<p>\n",
    "Apply Min-Max Scaling to the data, to prevent clustering to be biased towards parameters of greater magnitude. <br>\n",
    "All values should be between 0 and 1 after scaling, please check if this is true. <br>\n",
    "<br>\n",
    "\n",
    "For more information about MinMax Scaling, [Click Here!](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data: pd.DataFrame) -> np.array:\n",
    "    \"\"\"\n",
    "    Apply min-max scaling to the data to have all values between 0 and 1.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Bid statistics dataframe, containing all characteristic values of bidders in a given auction lot.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Normalized bid statistic data, ready to be used for clustering.\n",
    "    \"\"\"\n",
    "    # Only select characteristic values, namely NOB, ABP, HBP, Duration (excluding TOE and TOX as they are already scaled)\n",
    "    bid_stat_array = bid_statistic.iloc[:,3:8]\n",
    "    bid_stat_array.drop(['TOE', 'TOX'], axis=1, inplace=True)\n",
    "\n",
    "    # Initialize minmax scaler and apply to selected data\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    norm_bid_stat = min_max_scaler.fit_transform(bid_stat_array)\n",
    "\n",
    "    # Reappend the TOE and TOX values (as they were excluded upon selection)\n",
    "    norm_bid_stat = np.c_[norm_bid_stat, bid_statistic['TOE'], bid_statistic['TOX']]\n",
    "\n",
    "    return norm_bid_stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scale_data(data=bid_statistic)\n",
    "scaled_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> --- D3: Find number of clusters --- </h4>\n",
    "<p>\n",
    "A fundamental setp for any clustering algorithm is the determination of the optimal number of clusters into which the data needs to be clustered. <br>\n",
    "However, in most cases, the optimal amount of clusters is not known beforehand. <br>\n",
    "To decide the amount of clusters that is optimal with regards to the data, the Elbow Method will be used. <br>\n",
    "</p>\n",
    "\n",
    "For more information about the Elbow Method, [Click Here!](https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_method(scaled_data: np.array):\n",
    "\n",
    "    nr_of_clusters = list(range(1, 10))\n",
    "    within_cluster_variation = []\n",
    "    for amount in tqdm(nr_of_clusters):\n",
    "        within_cluster_variation.append(\n",
    "            KMeans(init='k-means++', n_clusters=amount).fit(scaled_data).inertia_\n",
    "        )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(nr_of_clusters, within_cluster_variation, color='red')\n",
    "    plt.xticks(nr_of_clusters)\n",
    "    plt.ylabel('Within Cluster Variation (WCV)')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.title('Elbow method')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow_method(scaled_data=scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Question</h4>\n",
    "<p>Q_D3: What is the best optimal number of clusters?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### \n",
    "# TODO: Read the optimal number of clusters from the Elbow plot above.\n",
    "###\n",
    "\n",
    "optimal_number_of_clusters = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> --- D4: Cluster the data --- </h4>\n",
    "<p>\n",
    "After deciding upon the optimal number of clusters, we run the KMeans algorithm once more to cluster the data. <br>\n",
    "Thereafter, we will combine the data and clustering labels into one pandas DataFrame. <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(init= 'k-means++', n_clusters=optimal_number_of_clusters, random_state=0).fit(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_statistic['cluster'] = kmeans.labels_\n",
    "bid_statistic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> --- D5: Extract cluster characteristics --- </h4>\n",
    "<p>\n",
    "Solemnly having the data clustered does not really have any descriptive business value. <br>\n",
    "What we want to see is what these clusters imply, which is done through extraction of cluster characteristics. <br>\n",
    "In a similar manner as we extracted the clustering characteristics, we can apply Pandas Groupby to extract these values. <br>\n",
    "What we would like to see is the following values for all clusters separately: \n",
    "<ol>\n",
    "    <li> Average NOB (Number of Bids) </li>\n",
    "    <li> Average ABP (Average Bid Price) </li>\n",
    "    <li> Average HBP (Highest Bid Price) </li>\n",
    "    <li> Average TOE (Time of Entry) </li>\n",
    "    <li> Average TOX (Time of Exit) </li>\n",
    "</ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_statistics = bid_statistic.groupby(['cluster']).agg({\n",
    "    'NOB': ['mean'], \n",
    "    'ABP': ['mean'], \n",
    "    'HBP': ['mean'], \n",
    "    'TOE': ['mean'], \n",
    "    'TOX': ['mean']\n",
    "    })\n",
    "\n",
    "cluster_statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> E: Predict sale or no-sale </h3>\n",
    "<p>\n",
    "After clustering (which is unsupervised learning) we are now going to apply supervised learning in the form of forecasting. <br>\n",
    "To improve the auction platform we want to automate the decision about what the starting bid should be. <br>\n",
    "For this, we will use a prediction model which predicts if a product will be sold. <br>\n",
    "By increasing the starting bid iteratively and continuously checking if a product will be sold, we can define a breaking point. <br>\n",
    "This breaking point is where the product goes from a sold prediction to an unsold prediction, which shows the highest starting bid which will result in a sell. <br>\n",
    "<br>\n",
    "\n",
    "This use case is of course greatly simplified, as the assumption that a higher starting bid will result in a higher final bid is quite a big one. <br>\n",
    "But for the sole purpose of testing whether you understand the fundamentals of supervised learning it will suffice. <br>\n",
    "What we want you to do is the following:\n",
    "<ol>\n",
    "    <li> Merge and preprocess the auction and lots data. </li>\n",
    "    <li> Create both a 70/30 training/test set (with random_state=0) of the lots dataset. </li>\n",
    "    <li> Initialize both the <code>LogisticRegression()</code> and <code>RandomForestClassifier()</code> using default settings and with random state 0. </li>\n",
    "    <li> Train both models using <code>.fit(X_train, y_train)</code>. </li>\n",
    "    <li> Predict the labels of the test set by using <code>.predict(X_test, y_test)</code>. </li>\n",
    "    <li> Calculate the model accuracy using the imported function and plot the confusion matrix. </li>\n",
    "    <li> Save the best performing model to a model.pkl file to be used later. </li>\n",
    "</ol>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> --- E1: Merge and preprocess the auction and lots data --- </h4>\n",
    "<p>\n",
    "First we are going to extract the desired columns from both the lots and auction data. <br>\n",
    "Thereafter we merge these tables, taking the lots data as our main table. <br>\n",
    "After merging two preprocessing steps need to be executed:\n",
    "<ul>\n",
    "    <li> Transform datetime objects into tangible numeric value. </li>\n",
    "    <li> Apply one-hot encoding to categorical variables. </li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve desired columns from lots and auction datasets\n",
    "# Lots_Sales_Pred = lots[['auctionID', 'lotNr', 'numberOfItems', 'estimatedValue', 'startingBid', 'reserveBid', 'sold']].copy()\n",
    "# Auctions_merge = auctions[['id', 'auctionStart', 'auctionEnd', 'branchCategory']].copy()\n",
    "\n",
    "# # Combine data into a single dataset\n",
    "# Lots_Sales_Pred = pd.merge(Lots_Sales_Pred, Auctions_merge, left_on=['auctionID'], right_on=['id'], how='left')\n",
    "# Lots_Sales_Pred_original = Lots_Sales_Pred.copy(deep=True)\n",
    "\n",
    "# Lots_Sales_Pred = Lots_Sales_Pred.dropna()  \n",
    "# Lots_Sales_Pred.drop('id', axis=1, inplace=True)\n",
    "# Lots_Sales_Pred\n",
    "\n",
    "# The merge is easier in a SQL query:\n",
    "sql_merge_query = \"\"\"\n",
    "                SELECT\n",
    "                    lots.auctionID, \n",
    "                    lots.lotNr, \n",
    "                    lots.numberOfItems, \n",
    "                    lots.estimatedValue, \n",
    "                    lots.startingBid,\n",
    "                    lots.reserveBid,\n",
    "                    lots.sold,\n",
    "                    auctions.auctionStart,\n",
    "                    auctions.auctionEnd,\n",
    "                    auctions.branchCategory\n",
    "                FROM lots\n",
    "                LEFT JOIN auctions ON \n",
    "                    lots.auctionID = auctions.id\n",
    "                  \"\"\"\n",
    "\n",
    "Lots_Sales_Pred = pandas_df_from_database(query=sql_merge_query)\n",
    "Lots_Sales_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform auctionStart and auctionEnd into a single column depicting the duration of the auction in hours\n",
    "Lots_Sales_Pred[['auctionStart', 'auctionEnd']] = Lots_Sales_Pred[['auctionStart', 'auctionEnd']].apply(pd.to_datetime, errors='coerce') \n",
    "Lots_Sales_Pred['auctionDuration'] = (Lots_Sales_Pred['auctionEnd'] - Lots_Sales_Pred['auctionStart']).apply(lambda x: abs(x/pd.Timedelta('1 hour')))\n",
    "Lots_Sales_Pred.drop(['auctionStart', 'auctionEnd'], axis=1, inplace=True)\n",
    "\n",
    "Lots_Sales_Pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have executed all manual transformations to the data, it is time to create the data <b>pipeline</b>. <br>\n",
    "<br>\n",
    "First we will create a numerical and categorical pipeline, after which we combine both and append a classifier to it. <br>\n",
    "To do this we create a function named <code>create_pipeline()</code>, as this allows us to create these pipelines dynamically. <br>\n",
    "This will be useful for the way we intend to test the two classification models mentioned before in a looping fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(scaler, encoder, clf, cat_col:list, num_col:list) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Take the imputer, scaler, encoder and classifier and create and return a sklearn pipeline.\n",
    "\n",
    "    Args:\n",
    "        scaler (_type_): Scaling module, used to scale the data to a set range of values.\n",
    "        encoder (_type_): Encoding module, used to transform categorical values to a workable format.\n",
    "        clf (_type_): Classification model, which can be any model from the sklearn classification model catalog.\n",
    "        cat_col (list): A list of the categorical columns that need to be transformed.\n",
    "        num_col (list): A list of the numerical columns that need to be transformed.\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: Pipeline containing all preprocessing and classification models.\n",
    "    \"\"\"\n",
    "    # 2 sub-pipelines, one for numeric features, other for categorical ones\n",
    "    numeric_pipe = make_pipeline(scaler)\n",
    "    categorical_pipe = make_pipeline(encoder)\n",
    "\n",
    "    # Using categorical pipe for feature State, numeric pipe otherwise\n",
    "    preprocessor = make_column_transformer((categorical_pipe, cat_col), \n",
    "                                            (numeric_pipe, num_col),\n",
    "                                            remainder='passthrough')\n",
    "    \n",
    "    return Pipeline(steps=[('preprocess', preprocessor), ('clf', clf)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> --- E2: Create both a 70/30 training/test set (with random_state=0) of the lots dataset. --- </h4>\n",
    "The quality of the supervised learning method is in a big way dependent on de amount of data that is available. <br>\n",
    "As we have to split the data into a train and test set, the set used for training the model also decreases in size. <br>\n",
    "For this reason it is a must to put this data to good use to get a reliable evaluation of the performance of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split the data in independent (X) and dependent (y) variables\n",
    "X_sale = Lots_Sales_Pred.copy().drop(['auctionID', 'lotNr', 'sold'], axis=1)\n",
    "y_sale = Lots_Sales_Pred['sold'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sale, y_sale, test_size=0.3, random_state=0)\n",
    "print(f'Created a training set containing {len(X_train)} records and a test set containing {len(X_test)} records')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4> --- E3: Initialize both the <code>LogisticRegression()</code> and <code>RandomForestClassifier()</code> using default settings and with random state 0. --- </h4>\n",
    "<h4> --- E4: Train both models using <code>.fit(X_train, y_train)</code>. --- </h4>\n",
    "<h4> --- E5: Predict the labels of the test set by using <code>.predict(X_test, y_test)</code>. --- </h4>\n",
    "<h4> --- E6: Calculate the model accuracy. --- </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One hot encode categorical variable to enable it to be used for forecasting\n",
    "Lots_Sales_Pred = pd.concat([Lots_Sales_Pred,pd.get_dummies(Lots_Sales_Pred['branchCategory'], prefix='BC')],axis=1)\n",
    "Lots_Sales_Pred.drop(['branchCategory'], axis=1, inplace=True)\n",
    "\n",
    "# # Min-max scale all numeric values to mitigate the effect of values being on different scales.\n",
    "scl = MinMaxScaler()\n",
    "Lots_Sales_Pred[['numberOfItems', 'estimatedValue', 'startingBid', 'reserveBid', 'auctionDuration']] = scl.fit_transform(\n",
    "     Lots_Sales_Pred[['numberOfItems', 'estimatedValue', 'startingBid', 'reserveBid', 'auctionDuration']]\n",
    "     )\n",
    "\n",
    "Lots_Sales_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing steps into variables\n",
    "scaler = MinMaxScaler()\n",
    "sclr_col = ['numberOfItems', 'estimatedValue', 'startingBid', 'reserveBid', 'auctionDuration']\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encd_col = ['branchCategory']\n",
    "\n",
    "classifiers = [\n",
    "     LogisticRegression(max_iter=5000, random_state=0),\n",
    "     RandomForestClassifier(random_state=0)\n",
    "     ]\n",
    "\n",
    "# Save predictions\n",
    "predictions_clf = {\n",
    "    'LogisticRegression': None,\n",
    "    'RandomForestClassifier': None\n",
    "    }\n",
    "\n",
    "# Test each different classifier\n",
    "for clf in classifiers:\n",
    "    name_clf = str(clf).split('(')[0]\n",
    "\n",
    "    # Combine with learning algorithm in another pipeline\n",
    "    pipe = create_pipeline(scaler, encoder, clf, cat_col=encd_col, num_col=sclr_col)\n",
    "    clf_pipe = pipe.fit(X=X_train, y=y_train)\n",
    "\n",
    "    # Save the predicted values in a list\n",
    "    predictions_clf[name_clf] = clf_pipe.predict(X_test)\n",
    "    \n",
    "    # Print the test accuracy\n",
    "    print(f\"{name_clf} test accuracy: {clf_pipe.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> --- E7: Plot the confusion matrix. --- </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Confusion Matrix: Logistic Regression')\n",
    "cm_logRes = confusion_matrix(y_test, predictions_clf['LogisticRegression'])\n",
    "disp = ConfusionMatrixDisplay(cm_logRes, display_labels=['Sold', 'Unsold']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Confusion Matrix: Random Forest Classifier')\n",
    "cm_rf = confusion_matrix(y_test, predictions_clf['RandomForestClassifier'])\n",
    "disp = ConfusionMatrixDisplay(cm_rf, display_labels=['Sold', 'Unsold']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['pred'] = predictions_clf['RandomForestClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[X_test['pred'] != 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lots_Sales_Pred.iloc[284251]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> --- Save the best performing model to a model.pkl file to be used later. --- </h4> \n",
    "\n",
    "As a best practice, once the best model has been selected, one should retrain it on the entire dataset. <br>\n",
    "You can still use a pipeline, add that classifier to the pipeline, retrain using all the data. Save the end model. <br>\n",
    "The end result is your entire data set was trained inside the full pipeline you desire. This makes it more robust. <br>\n",
    " In reality, this means you call <code>pipeline.fit()</code> and save the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Combine with learning algorithm in another pipeline\n",
    "pipe_to_save = create_pipeline(\n",
    "                    scaler=MinMaxScaler(),\n",
    "                    encoder=OneHotEncoder(),\n",
    "                    clf=RandomForestClassifier(random_state=0),\n",
    "                    cat_col=['branchCategory'],\n",
    "                    num_col=['numberOfItems', 'estimatedValue', 'startingBid', 'reserveBid', 'auctionDuration']\n",
    "                    )\n",
    "\n",
    "# Train on all data for better estimate\n",
    "trained_pipe = pipe_to_save.fit(X=X_sale, y=y_sale)\n",
    "\n",
    "# joblib save pipeline\n",
    "joblib.dump(trained_pipe, f\"trained_pipeline.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_train = list(X_sale.branchCategory.unique()) + ['numberOfItems', 'estimatedValue', 'startingBid', 'reserveBid', 'auctionDuration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_pipe.named_steps[\"clf\"].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = list(zip(columns_train, trained_pipe.named_steps[\"clf\"].feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>E: Implement AI Prediction into Create Lot</h3>\n",
    "<p>\n",
    "So far we created a simplistic prediction model and a database containing our data. <br>\n",
    "We also build APIs to communicate with our database, which also allow for the creation of new auctions, lots and bids <br>\n",
    "Our next task is to deploy our prediction model in the creation of a lot. <br>\n",
    "<br>\n",
    "\n",
    "When a new lot is created a fundamental step is to decide the starting price of the auctioned lot. <br>\n",
    "To make this data driven, your task is to implement the prediction model to automatically set an optimal price. <br>\n",
    "This is done through incrementally increasing the starting bid until the lot prediction of the lot goes from sold to unsold. <br>\n",
    "Implementing the automation of the starting bid is of course hugely simplified, as it acquiesces on the assumption that a higher starting bid will result in a higher final bid. <br>\n",
    "However, for the sole purpose of deploying an AI model it suffices. <br>\n",
    "<br>\n",
    "\n",
    "To execute this assignment, go to the directory called \"app\" and open the python file \"Services\". <br>\n",
    "Here you need to change the functionality of the <code>create_lot()</code> function. <br>\n",
    "Within this function some basis code is already given (which you have to uncomment), to get you up to speed.\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> --- Test the following auction: --- </h4>\n",
    "<ul>\n",
    "    <li> numberOfItems: 7 </li>\n",
    "    <li> estimatedValue: 100 </li>\n",
    "    <li> reserveBid: 1.0 </li>\n",
    "    <li> branchCategory : transport </li>\n",
    "    <li> auctionDuration: 250.0 </li>\n",
    "    <li> min_starting_bid: 5 </li>\n",
    "    <li> max_starting_bid: 155 </li>\n",
    "    <li> step_size: 5 </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>F: Dashboarding </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download SQLite ODBC driver\n",
    "- Download PowerBI\n",
    "\n",
    "- Press \"Get data\" and make an ODBC connection\n",
    "- Set DSN to None and open \"Advanced settings\"\n",
    "- Write a connection string, which is: DRIVER={SQLite3 ODBC Driver};Database=C:\\ [PATH TO THIS DIRECTORY] \\database.db;\n",
    "- Write something for username and password (as this is not checked but needed to go through)\n",
    "- Press \"Load Data\" to get the data into PowerBI\n",
    "- Fix many-to-many cardinality by creating additional column with auctionLotID in both Lots and Bids datasets\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4079134c0179285e3a55d2e425b94f441ed12cd55a998c83f6f5077fa904635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
