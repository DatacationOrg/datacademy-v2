{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacademy.modules import Module07\n",
    "\n",
    "#module = Module07(server_address='https://devdatacademyapi.azurewebsites.net')\n",
    "module = Module07(server_address='localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/Wholesale_customers_data.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## A. Data Understanding\n",
    "First we will get acquainted with the data, for which you have to follow the steps outlined in `Easy-LMS`. In between steps we allow you to validate the shape of your data frame, which enables you to check whether you executed the previous steps correctly. To do this, simply pass the `list(df.shape)` into the checker function, for which the code will be supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Investigate the first rows of the data frame using .head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Analyse the numerical values of the data frame using .describe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Analyse the different columns of the data frame using .info()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Generate a pairplot using the Seaborn library.\n",
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(df.loc[:, ~df.columns.isin(['Channel', 'Region'])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## B. Data Preparation\n",
    "Now we have an understanding of our data, we can continue with preparing our data. The steps to do this are outlined in `Easy-LMS`, so follow these accordingly. In between you can check your data frame shapes in a similar manner as before, to validate if you executed the steps correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Print the box plots of all columns except the 'Channel' and 'Region' column.\n",
    "plt.figure(figsize=(10,5))\n",
    "df_values = df.loc[:, ~df.columns.isin(['Channel', 'Region'])]\n",
    "boxplot = df_values.boxplot(column=list(df_values.columns))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Develop a function that removes outliers based on a dictionary of cut-off points.\n",
    "def remove_outliers(df:pd.DataFrame, cut_off:dict) -> pd.DataFrame:\n",
    "    \"\"\"Remove outliers of all columns given, based on the supplied cut-off points.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Original data frame.\n",
    "        cut_off (dict): Cut-off points of all columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Data frame with the outliers removed based on cut-off points.\n",
    "    \"\"\"\n",
    "    for c in cut_off.keys():\n",
    "        df = df[df[c] <= cut_off[c]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Set cut-off points and remove outliers.\n",
    "cut_off_dict = {\n",
    "    'Fresh': ..., \n",
    "    'Milk': ..., \n",
    "    'Grocery': ..., \n",
    "    'Frozen': ..., \n",
    "    'Detergents_Paper': ..., \n",
    "    'Delicassen': ...\n",
    "    }\n",
    "df = remove_outliers(df=df, cut_off=cut_off_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B1 - Validate Outlier Removal\n",
    "Execute the checker function below to evaluate if you executed the outlier removal steps correctly. The function will send the `maximum` values of all columns, as this will indicate whether the correct amount of outliers is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fill in the maximal values for all requested columns and validate them using the checker function.\n",
    "column_max_values = {\n",
    "    'Fresh': ..., \n",
    "    'Milk': ..., \n",
    "    'Grocery': ..., \n",
    "    'Frozen': ..., \n",
    "    'Detergents_Paper': ..., \n",
    "    'Delicassen': ...\n",
    "    }\n",
    "\n",
    "module.check(\"E1_B1\", column_max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Again print the box plots of all columns except the 'Channel' and 'Region' column.\n",
    "plt.figure(figsize=(10,5))\n",
    "df_values = df.loc[:, ~df.columns.isin(['Channel', 'Region'])]\n",
    "boxplot = df_values.boxplot(column=list(df_values.columns))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Apply the MinMax Scaler to our data frame.\n",
    "scaler = ...\n",
    "scaled_data = ...\n",
    "scaled_df = ...\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B2 - Validate Scaled Data\n",
    "Execute the checker function below to evaluate if you executed the scaling operation correctly. The function will send the `minimum`, `median` and `maximum` values of all columns, as this will indicate whether the values are correctly scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Run the code below to validate the statistic of the scaled data.\n",
    "scaled_df_stats={\n",
    "    \"min\": [round(x, 1) for x in np.min(scaled_df, axis=0)],\n",
    "    \"median\": [round(x, 2) for x in np.median(scaled_df, axis=0)],\n",
    "    \"max\": [round(x, 1) for x in np.max(scaled_df, axis=0)]\n",
    "}\n",
    "\n",
    "module.check(\"E1_B2\", scaled_df_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## C. Modeling and Evaluation\n",
    "Enough of the data preprocessing, it is time to develop and train a model! We will use the library `Scikit-Learn` to do so, more specifically the `KMeans()` algorithm. Please make sure that during initialisation (if possible) you set:\n",
    "* `random_state` = 0, to fixate the end result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Apply KMeans with 2 clusters to our scaled data frame.\n",
    "km = ...\n",
    "y_predicted = ...\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Print the cluster centers using the code below.\n",
    "km.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C1 - Validate Cluster Centers\n",
    "Execute the checker function below to evaluate if you created the clusters correctly. By checking the `cluster centers` we can identify whether the clusters are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Validate whether the cluster centers conform to our answers.\n",
    "module.check(\"E1_C1\", list([list(x) for x in km.cluster_centers_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Use code below to plot the cluster centers on a scatter plot.\n",
    "def plot_clustering(\n",
    "     df:pd.DataFrame,\n",
    "     kmeans:KMeans,\n",
    "     scaler:MinMaxScaler,\n",
    "     x_column:str,\n",
    "     y_column:str):\n",
    "\n",
    "        \"\"\"\n",
    "        Plot the output of the K-Means clustering algorithm using the given x and y columns.\n",
    "\n",
    "        Args:\n",
    "                df (pd.DataFrame): The unscaled data used for clustering.\n",
    "                kmeans (KMeans): The (trained) KMeans object.\n",
    "                scaler (MinMaxScaler): The used MinMaxScaler object.\n",
    "                x_column (str): Column name to plot along the X-axis.\n",
    "                y_column (str): Column name to plot along the y-axis.\n",
    "        \"\"\"\n",
    "\n",
    "        data = df.copy(deep=True)\n",
    "        data['clusters'] = kmeans.labels_\n",
    "\n",
    "        columns = list(data.columns)\n",
    "        centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "\n",
    "        # Plot all data points and their cluster assignment.\n",
    "        sns.scatterplot(\n",
    "        x=x_column,\n",
    "        y=y_column,\n",
    "        data=data,\n",
    "        hue='clusters')\n",
    "\n",
    "        # Plot the centroids of the K-Means algorithm.\n",
    "        sns.scatterplot(\n",
    "        x=centers[:,columns.index(x_column)],\n",
    "        y=centers[:,columns.index(y_column)],\n",
    "        color='red',\n",
    "        s=300,\n",
    "        marker='X')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Use the plot_clustering() function to analyse the clusters on different intersections of the data.\n",
    "plot_clustering(df=df, kmeans=km, scaler=scaler, x_column=\"Fresh\", y_column=\"Milk\")\n",
    "plot_clustering(df=df, kmeans=km, scaler=scaler, x_column=\"Fresh\", y_column=\"Grocery\")\n",
    "plot_clustering(df=df, kmeans=km, scaler=scaler, x_column=\"Frozen\", y_column=\"Grocery\")\n",
    "plot_clustering(df=df, kmeans=km, scaler=scaler, x_column=\"Milk\", y_column=\"Grocery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Apply KMeans on different amounts of clusters (1 to 10) and save the intertia_ parameter.\n",
    "K = ...\n",
    "WCV = []\n",
    "\n",
    "for k in K:\n",
    "    kmeans = ...\n",
    "    fitted_kmeans = ...\n",
    "    intertia = ...\n",
    "    WCV.append(intertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fill in the plot function to plot the value for K on the x-axis and the WCV on the y-axis.\n",
    "plt.plot(..., ...)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Within Cluster Variation (WCV)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C2 - Validate Optimal Amount of Clusters\n",
    "Execute the checker function below to evaluate if you decided on the correct value for optimal amount of clusters before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fill in the optimal amount of clusters and evaluate it using the checker function.\n",
    "optimal_amount_of_clusters = ...\n",
    "\n",
    "module.check(\"E1_C2\", optimal_amount_of_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Use the optimal amount of clusters and get the predicted clusters.\n",
    "km=KMeans(n_clusters=optimal_amount_of_clusters)\n",
    "y_predicted=km.fit_predict(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: For every column print a box plot, distinguishing between different clusters.\n",
    "clustered_df = df.copy(deep=True)\n",
    "clustered_df['cluster'] = y_predicted\n",
    "\n",
    "boxplot = clustered_df.boxplot(\n",
    "    column=[...], \n",
    "    by=..., \n",
    "    layout=..., \n",
    "    figsize=...\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Use the code below to print the cluster statistics.\n",
    "cluster_statistics = clustered_df.groupby(['cluster']).agg({\n",
    "    'Channel': ['mean'],\n",
    "    'Region': ['mean'],\n",
    "    'Fresh': ['mean'], \n",
    "    'Milk': ['mean'], \n",
    "    'Grocery': ['mean'], \n",
    "    'Frozen': ['mean'], \n",
    "    'Detergents_Paper': ['mean'],\n",
    "    'Delicassen': ['mean']\n",
    "    })\n",
    "\n",
    "cluster_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Run the code below to visualize your clusters in 3D plot(s).\n",
    "def plot_3d(df:pd.DataFrame, x:str, y:str, z:str, colors=('r', 'g', 'b', 'y')):\n",
    "    \"\"\"\n",
    "    Create a 3D scatter plot for the K-Means clustering results\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the (unscaled) data\n",
    "        x (str): Name of the column to plot along the X-axis\n",
    "        y (str): Name of the column to plot along the Y-axis\n",
    "        z (str): Name of the column to plot along the Z-axis\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row[x] < 20000 and row[y] < 30000 and row[z] < 30000:\n",
    "            ax.scatter(row[x], row[y], row[z], color=colors[row['cluster']])\n",
    "    \n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(y)\n",
    "    ax.set_zlabel(z)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d(df=clustered_df, x='Fresh', y='Milk', z='Grocery')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acc34b0575a7f16cdd3baafa50ebfc80b668b0c5be999b8d78070af1d779e7dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
